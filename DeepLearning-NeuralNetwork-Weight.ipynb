{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e225cfd",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; font-style: italic; font-family: sans-serif; text-align: center;\">Revolutionizing Recommendations as a Personalization Strategy:<p style=\"color:brown; text-align: center;\">Deep Learning - Neural Network Weight</p></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c28b54",
   "metadata": {},
   "source": [
    "### [Article: Revolutionizing Recommendations as a Personalization Strategy: Deep Learning](https://medium.com/@shukla.shankar.ravi/revolutionizing-recommendations-as-a-personalization-strategy-deep-learning-6b7d33804eb9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecbeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2bcbb56",
   "metadata": {},
   "source": [
    "# Deep Learning - Neural Network Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4033befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(9973)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bd9f7",
   "metadata": {},
   "source": [
    "## Step 1. Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43cbd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://grouplens.org/datasets/movielens/\n",
    "movies_df = pd.read_csv('./data/movies.csv')  # movieId, title, genres\n",
    "ratings_df = pd.read_csv('./data/ratings.csv')  # userId, movieId, rating, timestamp\n",
    "tags_df = pd.read_csv('./data/tags.csv')  # userId, movieId, tag, timestamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793eb34",
   "metadata": {},
   "source": [
    "## Step 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f66294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex userId and movieId to start from 0\n",
    "ratings_df['userId'] = pd.factorize(ratings_df['userId'])[0]\n",
    "ratings_df['movieId'] = pd.factorize(ratings_df['movieId'])[0]\n",
    "tags_df['userId'] = pd.factorize(tags_df['userId'])[0]\n",
    "tags_df['movieId'] = pd.factorize(tags_df['movieId'])[0]\n",
    "\n",
    "# Get unique values for number of users and number of movies\n",
    "num_users = ratings_df['userId'].nunique()\n",
    "num_movies = ratings_df['movieId'].nunique()\n",
    "\n",
    "# Incorporating Time-based Weightage for ratings\n",
    "# Convert timestamp to datetime format\n",
    "ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "\n",
    "# Calculate the weightage based on recency (more recent ratings should have higher weight)\n",
    "ratings_df['weight'] = (ratings_df['timestamp'].max() - ratings_df['timestamp']).dt.days + 1\n",
    "ratings_df['weight'] = 1 / (ratings_df['weight'])  # Inverse weighting: recent ratings get higher weight\n",
    "\n",
    "# Prepare input and target data for training\n",
    "user_ids = ratings_df['userId'].values\n",
    "movie_ids = ratings_df['movieId'].values\n",
    "ratings = ratings_df['rating'].values\n",
    "weights = ratings_df['weight'].values\n",
    "\n",
    "# Incorporate Tags: Most frequent tags for each movie\n",
    "# For simplicity, we'll take the most frequent tag for each movie and use it as a categorical feature\n",
    "tag_counts = tags_df.groupby('movieId')['tag'].value_counts().reset_index(name='count')\n",
    "tag_counts = tag_counts.loc[tag_counts.groupby('movieId')['count'].idxmax()]  # Keep the most frequent tag\n",
    "\n",
    "# Merge tags with ratings dataset\n",
    "ratings_with_tags = ratings_df.merge(tag_counts[['movieId', 'tag']], on='movieId', how='left')\n",
    "\n",
    "# Encode tags\n",
    "tag_encoder = LabelEncoder()\n",
    "ratings_with_tags['tag_encoded'] = tag_encoder.fit_transform(ratings_with_tags['tag'].fillna('Unknown'))\n",
    "\n",
    "# Prepare tags as additional input for the model\n",
    "tags = ratings_with_tags['tag_encoded'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346a5f7",
   "metadata": {},
   "source": [
    "## Step 3. Design Neural Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded2f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition (Using Keras Sequential)\n",
    "\n",
    "embedding_size = 50  # Size of the embedding vectors for users and movies\n",
    "\n",
    "# Define inputs\n",
    "user_input = layers.Input(shape=(1,), name='user')\n",
    "movie_input = layers.Input(shape=(1,), name='movie')\n",
    "tag_input = layers.Input(shape=(1,), name='tag')  # Input for tags\n",
    "\n",
    "# Embedding layers for users and movies\n",
    "user_embedding = layers.Embedding(input_dim=num_users, output_dim=embedding_size, input_length=1)(user_input)\n",
    "movie_embedding = layers.Embedding(input_dim=num_movies, output_dim=embedding_size, input_length=1)(movie_input)\n",
    "\n",
    "# Flatten the embeddings\n",
    "user_vec = layers.Flatten()(user_embedding)\n",
    "movie_vec = layers.Flatten()(movie_embedding)\n",
    "\n",
    "# Tag embedding\n",
    "tag_embedding = layers.Embedding(input_dim=len(tag_encoder.classes_), output_dim=embedding_size, input_length=1)(tag_input)\n",
    "tag_vec = layers.Flatten()(tag_embedding)\n",
    "\n",
    "# Concatenate the user, movie, and tag embeddings\n",
    "concat = layers.Concatenate()([user_vec, movie_vec, tag_vec])\n",
    "\n",
    "# Add a fully connected network (MLP)\n",
    "fc1 = layers.Dense(128, activation='relu')(concat)\n",
    "fc2 = layers.Dense(64, activation='relu')(fc1)\n",
    "output = layers.Dense(1)(fc2)  # Single output to predict the rating\n",
    "\n",
    "# Build the model\n",
    "model = models.Model(inputs=[user_input, movie_input, tag_input], outputs=output)\n",
    "\n",
    "# Compile the model with Adam optimizer and MSE loss function\n",
    "model.compile(optimizer=Adam(), loss='mse', weighted_metrics=['accuracy'])\n",
    "\n",
    "# Visualize Model\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d15230",
   "metadata": {},
   "source": [
    "## Step 4.  Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c379097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1261/1261 [==============================] - 30s 22ms/step - loss: 0.0019 - accuracy: 0.0160 - val_loss: 0.0013 - val_accuracy: 0.0214\n",
      "Epoch 2/10\n",
      "1261/1261 [==============================] - 17s 14ms/step - loss: 0.0011 - accuracy: 0.0162 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 3/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 8.3174e-04 - accuracy: 0.0161 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 4/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 7.3779e-04 - accuracy: 0.0162 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 5/10\n",
      "1261/1261 [==============================] - 16s 13ms/step - loss: 6.2079e-04 - accuracy: 0.0161 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 6/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 5.8150e-04 - accuracy: 0.0161 - val_loss: 0.0013 - val_accuracy: 0.0214\n",
      "Epoch 7/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 5.4517e-04 - accuracy: 0.0161 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 8/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 4.8948e-04 - accuracy: 0.0162 - val_loss: 0.0012 - val_accuracy: 0.0214\n",
      "Epoch 9/10\n",
      "1261/1261 [==============================] - 17s 13ms/step - loss: 4.6019e-04 - accuracy: 0.0161 - val_loss: 0.0014 - val_accuracy: 0.0214\n",
      "Epoch 10/10\n",
      "1261/1261 [==============================] - 16s 13ms/step - loss: 4.2813e-04 - accuracy: 0.0161 - val_loss: 0.0013 - val_accuracy: 0.0214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "train_user_ids, test_user_ids, train_movie_ids, test_movie_ids, train_tags, test_tags, train_ratings, test_ratings, train_weights, test_weights = train_test_split(\n",
    "    user_ids, movie_ids, tags, ratings, weights, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [train_user_ids, train_movie_ids, train_tags], train_ratings,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    sample_weight=train_weights,  # Use the weightage of ratings during training\n",
    "    validation_data=([test_user_ids, test_movie_ids, test_tags], test_ratings, test_weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41614fd",
   "metadata": {},
   "source": [
    "## Step 5. Generate Recommendations for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e781d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_movies_for_user(user_id, model, num_recommendations=10):\n",
    "    \"\"\"\n",
    "    Recommend top N movies for a given user based on predicted ratings from a trained model.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): ID of the user to recommend movies to.\n",
    "        model (keras.Model): Trained Keras model that predicts user-movie ratings.\n",
    "        num_recommendations (int): Number of top recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing recommended movie IDs and titles.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate an array of all possible movie IDs (e.g., from 0 to num_movies-1)\n",
    "    all_movie_ids = np.arange(num_movies)  # All movie IDs\n",
    "    \n",
    "    # Generate predicted ratings for the user and all movies\n",
    "    # Inputs: [user_id repeated for each movie, movie IDs, dummy input (e.g., zeros for tag or context)]\n",
    "    predicted_ratings = model.predict([np.array([user_id] * num_movies), all_movie_ids, np.zeros(num_movies)])\n",
    "    \n",
    "    # Sort movies based on predicted ratings (in descending order)\n",
    "    recommended_movie_ids = np.argsort(predicted_ratings.flatten())[::-1][:num_recommendations]\n",
    "    \n",
    "    # Get movie details for the recommended movie IDs\n",
    "    recommended_movies = movies_df.iloc[recommended_movie_ids]\n",
    "    \n",
    "    # Return just the movie ID and title for display\n",
    "    return recommended_movies[['movieId', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbf9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 1s 3ms/step\n",
      "Top 10 recommended movies for User 1:\n",
      "\n",
      "      movieId                                            title\n",
      "7659    88672                         Our Idiot Brother (2011)\n",
      "2872     3840                               Pumpkinhead (1988)\n",
      "3537     4835                     Coal Miner's Daughter (1980)\n",
      "6514    53894                                     Sicko (2007)\n",
      "4748     7072                                Stagecoach (1939)\n",
      "8135   101741                                    Trance (2013)\n",
      "258       298                  Pushing Hands (Tui shou) (1992)\n",
      "5240     8588                         Killing Me Softly (2002)\n",
      "4750     7074                            Navigator, The (1924)\n",
      "7678    89118  Skin I Live In, The (La piel que habito) (2011)\n"
     ]
    }
   ],
   "source": [
    "# Example: Get top 10 recommended movies for a user (say user_id=1)\n",
    "user_id = 1\n",
    "recommended_movies = recommend_movies_for_user(user_id, model, num_recommendations=10)\n",
    "\n",
    "print(f\"Top 10 recommended movies for User {user_id}:\\n\")\n",
    "print(recommended_movies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
